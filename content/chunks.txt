[0000s-0008s]:  So, hello everyone. Welcome to the PC Seminar. Today we have with us Professor Amir Mohad
[0008s-0012s]:  from American University of Beirut and he'll be talking on the girth and parametrious
[0012s-0017s]:  complexity of token sliding and token jumping. Thank you for joining us Professor. Over
[0017s-0023s]:  to you now. Thank you, President. Thank you for having me. It's a real pleasure to be
[0023s-0032s]:  here. So, all right, let's jump right into it. So, since I did not really know the audience
[0032s-0040s]:  too well, I made the assumption that many of you maybe have not seen this area of combinatorial
[0040s-0045s]:  reconfiguration problems. So, I decided what I'm going to do is I'm going to give a gentle
[0045s-0051s]:  introduction to the area just to show you how many exciting problems and open problems
[0051s-0058s]:  are there. And then I will talk more about token jumping and token sliding, specifically
[0058s-0063s]:  what we know about them, what we knew about them before we started working on this project,
[0063s-0069s]:  what we managed to discover and the tons of questions that remain to be answered.
[0070s-0077s]:  Right, and it's a really, I mean, the questions are so nice to stay, so easy to stay, and they
[0077s-0084s]:  are accessible really to researchers at any level, which is one of the reasons why I enjoy working
[0084s-0091s]:  on these problems. So, so hopefully you'll get to enjoy them too. So, before I start, I should
[0091s-0098s]:  point out that this is joint work that started back in the combinatorial reconfiguration workshop
[0099s-0106s]:  almost two years ago. And it's joint work with Valentine Bartet, Niko Labuske, Le Mandalard,
[0106s-0116s]:  and Karl Lomar, who is my master's student. All right, so the outline of the talk, it's going
[0116s-0122s]:  to be in four sections. I will give a gentle introduction to combinatorial reconfiguration,
[0122s-0131s]:  because I know many of you might not have seen such problems. Then I will talk about token jumping
[0131s-0136s]:  and token sliding, what we know about them in terms of classical complexity or one-dimensional
[0136s-0143s]:  complexity. Then I'll talk about the param-joice complexity of these two problems and what we know
[0143s-0150s]:  as of today, as we speak, and what are the problems that remain to be solved. And then the last part
[0150s-0154s]:  of the lecture is where I will put some of the technical stuff to show you to give you an idea
[0155s-0160s]:  about how we prove things when we deal with such problems and where are the difficulties
[0160s-0166s]:  and what kind of techniques have been developed. So I tried to keep the technical part as light as
[0166s-0174s]:  I could so that really, I mean, I can focus on the big picture and the questions to be asked
[0174s-0180s]:  and answered. So if you have any questions along the way, please feel free to interrupt me either
[0180s-0188s]:  in the chat or by unmuting yourselves. So don't worry about leaving the questions to the end,
[0188s-0192s]:  you can interrupt me whenever you feel, whenever I say something that doesn't make sense.
[0193s-0199s]:  Hopefully that won't happen too often. All right, so what is combinatorial reconfiguration?
[0199s-0206s]:  So the best way I think to introduce is with a familiar example, which is one player games,
[0206s-0212s]:  and the most common one that we use is the 15 puzzle game. So for those of you who don't know
[0212s-0219s]:  the 15 puzzle game, so you're given like a four by four grid and you have one empty square.
[0220s-0225s]:  And basically you have all the remaining 15 squares are numbered from one to 15 and they come
[0225s-0232s]:  in some ordering and your job is to basically move the squares around so that all the numbers become
[0232s-0238s]:  ordered. So it's a by-ro, so they have to be ordered this way. So if you notice in this figure,
[0238s-0245s]:  the only problem is that 14 and 15 are reversed. But the only moves that you're allowed to do is
[0245s-0254s]:  to basically move a number into the empty square. And basically you have to do a sequence of moves
[0254s-0260s]:  so that you get all of the numbers in order. And for those of you who know this this game,
[0260s-0268s]:  this example that I have on the slide is actually unsolved. There is no way you can flip the order
[0268s-0274s]:  and 15 of 14 and 15 in this puzzle. And I have a link here if you want to actually play the
[0274s-0281s]:  puzzle online, which is pretty fun. So why do I do I start my talk by talking about 15 puzzle? It's
[0281s-0288s]:  because it's really, I mean the way you solve the 15 puzzle tells you a lot about the area of
[0288s-0296s]:  combinatorial reconfiguration. So the standard way we would think about the 15 puzzle is by looking
[0296s-0302s]:  at the state space or what we call the reconfiguration graph of the 15 puzzle. So what does that graph
[0302s-0310s]:  consist of? Well, we have one vertex or one node in this graph for each possible configuration of
[0310s-0316s]:  the puzzle. So basically each possible configuration, so it would be a possible permutation of the 15
[0316s-0323s]:  numbers. In addition to where you're going to put the empty square, each one of those will be a vertex
[0323s-0330s]:  and the graph. And now we connect two vertices in that graph whenever one can be reached from the
[0330s-0336s]:  other by a single move. And what do we mean here by a single mover? It's basically just moving
[0337s-0344s]:  number into the empty square. So if you look at the top node here in this graph, there are four
[0344s-0349s]:  possibilities that you can do in one move, which we call a reconfiguration step, which is you can
[0349s-0356s]:  move nine into the empty square, you can move three into the empty square, 12 or 15.
[0356s-0360s]:  And that gives us basically four neighbors of that vertex in the graph.
[0361s-0367s]:  Okay, and we call this whole graph, the reconfiguration graph or the state space if you're more
[0367s-0375s]:  comfortable thinking about states, the states of the game. So now given this graph, the reconfiguration
[0375s-0381s]:  graph, there are tons of very interesting questions that you can ask about it. There are structural
[0381s-0387s]:  questions and there are algorithmic questions. And these are typically the types of questions that
[0387s-0395s]:  were interested in in this area of combinatorial reconfiguration. So a couple of examples of structural
[0395s-0401s]:  questions would be, well, the simplest one would be how big is this reconfiguration graph,
[0401s-0408s]:  right, how many vertices or how many edges. And that's usually not a very hard question to answer
[0408s-0414s]:  in terms of upper and lower ones. More interestingly, you can ask, is this reconfiguration graph
[0414s-0422s]:  connected, right? Or is, can I reach any state starting from any other state by a sequence of legal
[0422s-0429s]:  moves? And as I told you before, for the 15 puzzle, the reconfiguration graph is definitely not
[0429s-0435s]:  connected because there was no way to reverse 14 and 15 in the previous example that I showed you
[0435s-0440s]:  and you can easily prove that, by the way. So when it's not connected, another question would be how
[0440s-0448s]:  many components does I have? Is there some sort of a nice structure to the components of this graph?
[0450s-0455s]:  And then another question would be what is the diameter of the circumfiguration graph or of each
[0455s-0459s]:  one of its components? And that's usually a very important question to ask when you're dealing with
[0459s-0466s]:  one player games, because this could tell you like what would be the worst possible shortest path
[0466s-0472s]:  to reach a target configuration or to solve your game, to win your game, for example. And in the
[0472s-0479s]:  literature, this is sometimes known as God's number, which would be the diameter of the reconfiguration
[0479s-0485s]:  graph. And these are all very interesting, very interesting structural questions to ask about
[0485s-0492s]:  this reconfiguration graph. Now on the algorithmic side or the computational side, there's the
[0492s-0498s]:  obvious question of if I'm given a starting state and some ending state or target state, like in
[0498s-0504s]:  the case of the puzzle game, that I am given some starting state and we know what the goal state is.
[0505s-0510s]:  So here one decision problem would be to answer the question whether it's possible to get to the
[0510s-0517s]:  target state starting from some initial state that is also given to me. So you can decide to solve
[0517s-0521s]:  this problem either as a decision problem or as a search problem, which would give you the actual
[0521s-0531s]:  sequence of steps that will take you from a state to the target state. Other interesting computational
[0531s-0537s]:  problems is it always possible to go from one configuration to any other and this is basically
[0537s-0545s]:  also related to the structural question about connected components. And the last question that I
[0545s-0551s]:  would mention, which is also interesting, is how fast can you go from one configuration to another,
[0551s-0560s]:  meaning can you do it in at most case steps? There is a question I should wait or no,
[0560s-0573s]:  all right. So think about all of these questions that we paused using the simple 15 puzzle game.
[0573s-0581s]:  And now we're going to look at a lot of other possible problems where the same any configuration graph
[0581s-0588s]:  can be extracted and we can ask the same set of questions. So all of you here are familiar with the
[0588s-0595s]:  case sad problem. So you're given a Boolean formula and you want to know if you can satisfy this
[0595s-0601s]:  formula by assigning values to the variables and we know that this is NP complete for K greater than
[0601s-0607s]:  or equal to three. So now how can you transform this into a reconfiguration problem? Well, it's very
[0607s-0615s]:  simple. So now you're given a formula and you're given two satisfying assignments. So you can think
[0615s-0621s]:  of those satisfying assignments as bit vectors. And so now the question that you can ask is,
[0621s-0629s]:  can I go from the first satisfying assignment as to the next one? By basically flipping one bit at a
[0629s-0637s]:  time under the condition that I remain a satisfying assignment at all times. And notice that without
[0637s-0644s]:  this condition, the problem is trivial. So you can basically just flip the bits however you like
[0644s-0652s]:  and reach S from T or T from S. But once you have this constraint of you should remain a satisfying
[0652s-0658s]:  assignment, the problem becomes way more interesting. And you can think of this problem again as
[0658s-0665s]:  walking in the solution space of the given formula of all the satisfying assignment of the formula F.
[0666s-0674s]:  All right, so that's the sad reconfiguration problem. Let's look at another example.
[0675s-0683s]:  Graph coloring. We all know it. We all love it. You're given a graph and some integer K and you are
[0683s-0689s]:  asked whether you can properly k color the graph G. And we know again that this is NP complete for
[0689s-0694s]:  K greater than or equal to three. How do you transform that into a reconfiguration problem? Well,
[0695s-0701s]:  now you're given a graph. You're given two colorings of the graph alpha and beta. And the question is,
[0701s-0709s]:  can you recolor alpha to get the to beta? But you need to recolor one vertex at a time and you need
[0709s-0717s]:  to remain a proper K coloring throughout. Same idea again leads us to this notion of the reconfiguration
[0717s-0723s]:  space where we are looking at the K colorings of the graph and how they are connected
[0724s-0729s]:  under this adjacent simulation that we define, which is a single vertex recoloring.
[0731s-0737s]:  The final example that I will mention, which will be basically what we will focus on in the rest
[0737s-0743s]:  of the talk is token placement. I call it, but as you will all guess, this is the famous independent
[0743s-0749s]:  set problem. But we will look at it as a token placement problem because it will be more useful
[0749s-0754s]:  for the rest of the talk. So you're given a graph G and an integer K. And the question is,
[0754s-0760s]:  can you place K tokens on your graph K black tokens so that no two of these tokens share an edge.
[0760s-0766s]:  And of course, we all know that this is an NP complete problem. So how can you transform this
[0766s-0772s]:  problem into a reconfiguration problem? Again, now I'm giving a graph two independent sets of the
[0772s-0778s]:  graph each of size K. And the question is, can I go from one independent set to the other
[0780s-0787s]:  under what rule? So here defining the rule for independent set, how can I go between consecutive
[0787s-0794s]:  independent sets becomes a little bit less obvious. And there are two main strategies that people
[0794s-0800s]:  have attempted. So the first rule is what we call token jumping. So you are basically allowed
[0800s-0807s]:  to take any token on your graph and jump it to any other vertex on the graph assuming that it
[0807s-0814s]:  doesn't have a token and that you maintain an independent set at all times. So for example, in this
[0815s-0821s]:  example that I have here, it would be perfectly okay to take this token here and jump it to this
[0821s-0829s]:  vertex here. Or I could also take this token here and jump it to this vertex here.
[0830s-0837s]:  So that, no, actually that would violate the independence. So you can jump to any other vertex as
[0837s-0843s]:  long as you maintain independence. And we call that the token jumping rule. The other rule is
[0843s-0850s]:  basically token sliding. So in this case, we only allow a token to slide along edges of the graph.
[0851s-0860s]:  So a token can only move to adjacent vertex assuming of course this does not violate independence.
[0860s-0865s]:  So now we have two different reconfiguration graphs we can think about. We can think about the
[0865s-0871s]:  reconfiguration graph under the token jumping adjacency. And we can think about the reconfiguration
[0871s-0877s]:  graph under the token sliding adjacency. And we're going to talk about these two different problems
[0877s-0884s]:  because they do actually behave quite differently and they produce quite interesting results. Like the
[0884s-0889s]:  difference between the two, we don't fully understand yet, but we kind of know that token sliding
[0890s-0895s]:  can be harder than token jumping. But there's still a lot of questions to be answered.
[0898s-0903s]:  All right. So some of you might be asking why do we care about studying such problems?
[0904s-0913s]:  There's a lot of motivations out there. I mean, as sometimes I would say you don't need motivation,
[0913s-0918s]:  they're interesting. There's a lot of open questions that we need to answer. But you can also
[0918s-0924s]:  think about reconfiguration problems as another way of modeling real world algorithmic problems
[0924s-0929s]:  because you usually never start from scratch. When you're trying to solve real world problems,
[0929s-0934s]:  you usually start from something and you're trying to prove it or make it better or change it to
[0934s-0942s]:  something more appropriate. Another very good application of studying these problems is that they
[0942s-0948s]:  give you a better understanding of solution spaces, which can be very important for other areas as
[0948s-0953s]:  well. And they have been used in statistical physics, quantum computing, and complexity theory,
[0953s-0960s]:  combinatorics, and robotics, and hopefully many more applications to come. But what I would tell you
[0960s-0965s]:  is that there are so many very interesting problems that are so easy to start thinking about without
[0965s-0971s]:  having too much background, which is what I think this is a very nice area to start working on
[0972s-0975s]:  at any level in your research career.
[0979s-0985s]:  All right, so I'll take a break here and take questions if there are any. And then we will dive into
[0985s-0992s]:  the token jumping and token sliding problems, what we know about them in terms of classical complexity,
[0992s-0997s]:  and what was basically the starting point for the project that led us to this paper.
[1000s-1001s]:  Any questions at this point?
[1002s-1011s]:  I'm, I'll apologize for the small context, which I'm interrupting here. So this is just to
[1011s-1017s]:  announce for the PC 301 workshop that will be happening in December end. And this will be slightly
[1017s-1023s]:  different from the previous two workshops. First major difference, this will be online. Second is
[1023s-1031s]:  some advanced topics, what we discuss. So anyone who intends to explore somewhat more complex
[1031s-1038s]:  topics in parametrize algorithms is invited to have a check. We can look at the website that
[1038s-1043s]:  has been shared on the chat. And if you wish, you can register simply by filling a form that is
[1044s-1050s]:  linked at the bottom of the webpage. So just to inform you all about it. And sorry for the
[1051s-1060s]:  questions. Now, I'll give you a counter. All right. All right. So let's start talking about
[1061s-1067s]:  token jumping, token sliding, and a little bit about classical complexity. I know everybody
[1067s-1072s]:  here knows about P and NP, so I'm not going to talk about this. Some of you might not be familiar
[1072s-1077s]:  with the PSPACE class. So just a quick note, that's as much as you will need to know for this
[1078s-1085s]:  talk, is that PSPACE is the set of all decision problems that can be solved using a polynomial
[1085s-1091s]:  amount of space. And the reason why I mentioned this class is because many, many, many, many
[1091s-1099s]:  reconciliation problem actually are PSPACE complex. Okay. And so, so what we know, the standard
[1099s-1104s]:  inclusion is we know that P is contained in NP, which is contained in PSPACE. But a very
[1104s-1112s]:  useful thing about PSPACE is that savage prove that it's equal to NP space. So polynomial space
[1112s-1118s]:  and non deterministic polynomial space are the same class. Basically, and that's extremely useful
[1119s-1123s]:  when you start to think about reconfiguration problems, because if you think about reconfiguration
[1123s-1130s]:  problem, where you're given some state and you want to reach the other one. So basically,
[1130s-1137s]:  you can solve that easily in non deterministic polynomial space, which basically implies that
[1137s-1144s]:  they are in PSPACE. But actually, you can show a lot more than that. You can show that many,
[1144s-1149s]:  really many reconfiguration problems are actually PSPACE complete, which is not surprising.
[1150s-1157s]:  Right. The fact that many of these reconfiguration problems are PSPACE complete is not very surprising.
[1157s-1164s]:  Right. And then, then not being in NP is because they don't always have polynomial size certificates,
[1164s-1170s]:  which also makes sense. Because sometimes, the number of steps that you need to take to go from
[1170s-1176s]:  one configuration to the other might very well be exponential in the graph. But there are also
[1176s-1182s]:  some extremely surprising results. And these are some of the results, some of my favorite results in
[1182s-1189s]:  the area. So for example, you all know that coloring is NP complete even for k equals 3.
[1190s-1196s]:  However, it turns out that if you try to solve the recoloring problem for k equals 3,
[1197s-1203s]:  it's actually polynomial time-solvable. So if I give you two three colorings of a graph and I ask
[1203s-1210s]:  you, is there a path between them that recolors one vertex at a time and is always a valid three
[1210s-1216s]:  coloring, then this problem can be solved in polynomial time. And the recoloring problem only
[1216s-1225s]:  becomes PSPACE complete for k equals 4 and more. Right. So that's the first surprising result.
[1225s-1232s]:  Another very surprising result is that as your all FBT experts here, I know that you're
[1232s-1237s]:  all familiar with the fact that usually when we study problems on graphs of bounded bucket width,
[1237s-1246s]:  path width, tree width, they tend to become easier. It turns out that that's not really the case
[1246s-1251s]:  for reconfiguration problems, at least for token sliding and jumping, which is the two problems
[1251s-1257s]:  that are related to independent set. It turns out that those two problems remain PSPACE complete
[1257s-1261s]:  even if you have a graph of constant tree width or path width or even bucket width.
[1262s-1268s]:  So a very, very, very simple graph structure still the problem remains hard.
[1271s-1278s]:  All right. And finally, the last theorem that I also like a lot shows you basically that
[1278s-1286s]:  sliding and jumping behave differently. And it was shown that if you restrict yourself to
[1286s-1291s]:  bipartite graphs, where we know that max and independent set can be solved in polynomial time,
[1292s-1298s]:  if you restrict yourself to those graphs, it turns out that token jumping is NP complete,
[1299s-1309s]:  whereas token sliding is PSPACE complete, which is a strange difference between the behavior
[1309s-1321s]:  of those two problems. All right. So in fact, we know a lot more about token sliding and
[1321s-1327s]:  token jumping. These problems have been at the heart of the area of combinatorial reconfiguration.
[1327s-1333s]:  They have been studied so much. And we know so much about them at least in terms of standard
[1333s-1342s]:  or classical complexity. So some of the important results for our paper that we're going to focus on
[1343s-1350s]:  is this result. So that's going to be the starting point of the results that we will discuss
[1350s-1355s]:  next when we move to parametrize complexity. So the fact that token sliding and token jumping
[1356s-1361s]:  are PSPACE complete and then NP complete respectively on bipartite graphs was the starting point
[1361s-1366s]:  of our next paper. But there are some very interesting results here that are also worth mentioning.
[1366s-1372s]:  So for example, for even whole figure half we know how to solve token jumping in polynomial time.
[1373s-1378s]:  But the complexity of independent set even remains open on this class of graphs.
[1379s-1385s]:  And the complexity of token sliding also remains open. So we don't know how to check if given
[1385s-1391s]:  two independent sets, I can slide one to the other. Can you answer that question in polynomial
[1391s-1399s]:  time for even whole free graphs? For split graphs and chordal graphs, they also behave extremely
[1399s-1405s]:  differently token sliding and token jumping. So they are token sliding is PSPACE complete on
[1405s-1412s]:  split graphs and chordal graphs while token jumping is polynomial time. And that is some of the
[1412s-1419s]:  reasons why we feel that token sliding is harder usually than token jumping. But it's not always the
[1419s-1433s]:  case. All right. So that's it for classical complexity. So now let's move on to parametrize complexity.
[1433s-1439s]:  And let's basically think about how you can parametrize those two problems token jumping and
[1439s-1446s]:  token sliding. So there's the obvious parameter would be the number of tokens. So one of the obvious
[1446s-1453s]:  parameters would be the number of tokens. So and we're going to denote that by K. Another parameter
[1453s-1458s]:  would be the length of the sequence. Like how many steps does it take to go from one independent set
[1459s-1465s]:  to the other? You can also obviously parametrize by tree width or path width or any combination of
[1465s-1474s]:  the above. When we started working on this problem, our initial aim was to basically study the
[1474s-1480s]:  parametrize complexity of token sliding and token jumping on bipartite graphs using the parameter K
[1480s-1486s]:  number of tokens. Right. Because remember, we saw that token sliding is PSPACE complete on
[1486s-1493s]:  bipartite graphs and token jumping is NP. So you were interested to see if basically this is going
[1493s-1499s]:  to give us W1 hardness for token sliding and fptness for token jumping.
[1499s-1505s]:  All right. At least that was the initial hope. That's why we started working on this project.
[1506s-1511s]:  We weren't able to answer the two questions. So we were able to answer one side of the question,
[1512s-1520s]:  which is we were able to show that on bipartite graphs token sliding is in fact W1 hardness.
[1522s-1528s]:  So token sliding parametrize by the number of tokens on bipartite graphs is W1 hardness.
[1528s-1535s]:  We were not able to answer the question for token jumping. So that is still an open question.
[1537s-1542s]:  So having answered that question and failed on the next question, we started thinking about ways
[1542s-1549s]:  to basically simplify a little bit some of these questions. So the next thing we asked ourselves,
[1549s-1556s]:  so there are two directions where you can try and simplify. So the next thing we asked
[1556s-1562s]:  ourselves was, okay, so from bipartite graphs, how can I go to other classes of graphs
[1564s-1571s]:  and see where token jumping becomes hard or easy? And it turned out that if you basically exclude
[1571s-1580s]:  only C4 from your graph, right? And so we, because in bipartite graphs, you're excluding all
[1580s-1588s]:  cycles, right? So we started thinking about what kinds of cycles affect the behavior of those
[1588s-1594s]:  problems. So the first question was, what about C4 free graphs? And it turned out that both problems
[1594s-1603s]:  remained W1 hard on C4 free graphs. Now if you exclude C3 and C4, it turns out that token jumping
[1603s-1611s]:  becomes FPT has an order K squared kernel, but for token sliding, we were not able to determine the
[1611s-1620s]:  complexity. Now if you go to the other side of that, so what if we enforce both bipartite
[1620s-1629s]:  tightness as well as C4 freeness? So in that case, we were able to show that both problems became FPT.
[1633s-1639s]:  Okay, and basically the bipartite bounded degree graphs was just a stepping stone to get to the
[1639s-1647s]:  bipartite C4 free graph result. So let me, let me repeat that maybe slightly more clearly. So after
[1647s-1652s]:  basically answering the first question, which was bipartite graphs, we were able to show that token
[1652s-1659s]:  sliding was W1 hard, but we were not able to determine the complexity of token jumping. So then we
[1659s-1666s]:  went to C4 free graphs, and we were able to show that both problems are actually W1 hard. Then if we
[1666s-1673s]:  added one more constraint, which was C3 C4 free graphs, we got FPT-nits for token jumping, but it
[1673s-1681s]:  remained open for token sliding. And on the other side of the spectrum, so if we keep bipartite
[1681s-1691s]:  and enforce the C4 freeness, we get FPT for both problems. And as a side note, this blue result
[1691s-1702s]:  is not part of our paper. This was known prior to our paper. So any questions about the results?
[1704s-1729s]:  No questions. All right, cool. So lots of open problems. The first and obvious one is,
[1729s-1734s]:  what is the pattern is token jumping FPT, but I'm trying to buy K on bipartite graphs.
[1735s-1741s]:  And that's really, I mean, that was the initial question that we set out to answer and couldn't.
[1741s-1752s]:  So that remains open. And it's, so I will not be going over the hardness reduction for
[1752s-1756s]:  token sliding on bipartite graphs, because it's quite technical. I don't feel a talk is the
[1756s-1766s]:  right place to go over it. But if you go over the reduction, you will see that it's the two
[1766s-1771s]:  problems really behave differently. And there's that doesn't seem to be a chance to basically make
[1771s-1778s]:  the same type of reduction work for token jumping. So the second interesting open question is,
[1778s-1784s]:  how about token jumping parameterized by K on triangle free graphs? That's basically even more
[1784s-1791s]:  general than question one. Right. So, and the reason why I mentioned this question separately is
[1791s-1798s]:  because almost every reduction that I know of includes large clicks. So you need to use large
[1798s-1805s]:  clicks in your reductions. So how about if we don't allow triangles and large clicks? So can we,
[1805s-1812s]:  can we can we then say something about the problem? So that's for token jumping. Now when when you go
[1812s-1819s]:  to token sliding. So so the open problem is what happens for token sliding on graphs of
[1819s-1827s]:  girth at least five. So if they are C3 C4 free, or you can even make that a bit weaker and ask for
[1827s-1836s]:  any girth of at least P for some constant P. And for all of these questions, of course, polynomial
[1836s-1844s]:  kernels would be interesting as well. Because in our case, we do get polynomial kernels for the FB.
[1847s-1853s]:  The polynomials are not great, but polynomial regardless.
[1856s-1864s]:  All right. So in the rest of the talk, I will try to cover some of the technical stuff. And as promised,
[1864s-1870s]:  I will try to keep it as light as possible so that I can give you some of a lot of the intuition
[1870s-1876s]:  and techniques that are used in this paper and that are generally used when dealing with
[1876s-1882s]:  reconfiguration problems. So the first result that we will go over is this W hardness on C4 free
[1882s-1888s]:  graphs. Right. For both token sliding and token jumping. It's the same reduction and and
[1889s-1895s]:  you will get both results because we will be using maximum independent sets.
[1896s-1903s]:  So if you're trying to basically do token sliding from one maximum independent set to the other,
[1903s-1908s]:  or token jumping, these two rules become equivalent, jumping becomes equivalent to sliding.
[1909s-1914s]:  So when you're dealing with maximum independent sets, these two basically rules are the same.
[1915s-1919s]:  And that's what we're going to do. But what we're going to prove actually is a stronger
[1919s-1925s]:  theorem. What we're going to prove is the following theorem. If you take any p greater than or
[1925s-1935s]:  equal to four, then both problems are W hard on C4, C5 dot dot dot up to Cp free graphs,
[1935s-1946s]:  which implies of course C4 free graphs. But you can basically exclude any cycles from C4 up to
[1946s-1959s]:  Cp for constant P and the problems will remain W1 hard. So how do we prove this result? In fact,
[1959s-1966s]:  we use a known reduction from a problem known as grid tiling, which is a W1 hard problem.
[1967s-1974s]:  And grid tiling is reduced to the independent set problem on C4 up to Cp free graphs.
[1975s-1983s]:  And that reduction was used to show that independent set remains W1 hard if you exclude C4 up to
[1983s-1992s]:  Cp for any constant P. But what is interesting and useful in that reduction is the graph that is
[1992s-1999s]:  obtained from the reduction. So the graph that is obtained from the reduction has three properties
[1999s-2004s]:  that are going to be useful to us. The first property is that you can partition the graph
[2005s-2013s]:  into basically 8k squared into p plus 1 clicks. So you have a bunch of clicks, each of size n,
[2013s-2021s]:  and all of the edges basically are between the clicks. But that's it, that's the whole of the graph.
[2021s-2029s]:  It's a bunch of clicks and edges between them. Of course, the more important property as well here
[2029s-2037s]:  is that this graph is going to be C4 up to Cp free. It will not have any of those cycles as an
[2037s-2046s]:  induced subgraph. And it's an equivalent instance to the grid tiling. And that basically gives you
[2047s-2055s]:  a W1 hardness of independent set on this class of graphs. So notice in this case that an
[2055s-2061s]:  independent set of size 8k squared into p plus 1 will have to be a maximum independent set,
[2061s-2066s]:  because that's how many clicks we get in the resulting graph. And that's basically the sizes
[2066s-2071s]:  that we will be working with, more or less up to some modifications. But this will allow us to
[2071s-2078s]:  basically conclude that both sliding and jumping are hard on this class of graphs.
[2081s-2088s]:  So how do we use this for showing hardness of token sliding and token jumping? And let's focus
[2088s-2094s]:  on token sliding for now, because it's going to be the same anyway. So we have those clicks
[2095s-2102s]:  and some edges that go between the clicks. So the first attempt would be as follows. We will add
[2102s-2108s]:  a universal vertex to each one of the clicks and we will call this the starting set or the starting
[2108s-2114s]:  independent set. And then we add another universal vertex to each one of the clicks and call this
[2114s-2120s]:  the target independent set. And now basically we have our instance of token sliding. We want to
[2120s-2130s]:  slide everybody in S down to T. So notice that this is useful because we don't introduce any of
[2130s-2137s]:  the forbidden cycles. So we are still fine. And if we could guarantee that all of the tokens
[2137s-2144s]:  will be on the on the clicks simultaneously, then this will imply an independent set in the
[2144s-2150s]:  original graph, which concludes our proof. But unfortunately in this case, we definitely cannot
[2150s-2158s]:  conclude that because each rent token can slide independently here and then here and then the next
[2158s-2167s]:  one can follow, etc, etc, etc. So you need some way of forbidden, or forbidding these tokens to
[2167s-2174s]:  behave freely. We want to make sure that they will all be inside the clicks simultaneously and we
[2174s-2180s]:  will be done. And notice that we're going to have 8K squared and 2P plus 1 tokens, right? 1 for each
[2180s-2188s]:  click and 2 universal vertices for each click. So how do we fix this simultaneously issue?
[2189s-2195s]:  Well, here's how we can do it. So instead of simply adding universal vertices,
[2196s-2202s]:  we're also going to add an edge between every two universal vertices on a click. And then we're
[2202s-2209s]:  going to add something that we call a switch. And in this case, it's a simple edge and the red token
[2209s-2217s]:  here needs to go to the blue position. Right? So now we have one extra token inside our graph.
[2217s-2227s]:  But now notice what happens. If any red token wants to come to the blue position, then this red
[2227s-2234s]:  token needs to be moved to this position before. And if you move that token up to the blue position,
[2234s-2240s]:  then you can no longer have any of the red tokens on the universal vertices, which means that they
[2240s-2247s]:  will all have to be simultaneously inside the clicks. And now we get the behavior that we want.
[2249s-2254s]:  So now we can guarantee that if there is a sequence that takes the red tokens to the blue position,
[2256s-2263s]:  then somewhere along that sequence, the tokens are all going to be within the clicks. Unfortunately,
[2263s-2268s]:  what happened here is we might have introduced some of the forbidden cycles. We can no longer
[2268s-2277s]:  guarantee that this is c4 up to cp3. So what you can do in this case to solve this problem,
[2277s-2282s]:  and I'm not going to go into the details, but the intuition should be pretty clear, is that you can
[2282s-2289s]:  subdivide those edges, make them long enough so that you don't introduce any forbidden cycles,
[2289s-2293s]:  and add appropriate tokens inside of them to get the same behavior.
[2293s-2299s]:  Because notice that the number of such edges is bounded by a function of k,
[2300s-2310s]:  by a function of yes k and p. This case. Right, so you can make these edges subdivide them as many
[2310s-2316s]:  times as needed, add as many tokens as needed to maintain all the properties that we need,
[2316s-2319s]:  and to maintain that we're going from one maximum independent set to the other,
[2320s-2325s]:  which will give you W1 hardness for both token sliding as well as token jumping.
[2331s-2337s]:  All right, questions?
[2337s-2342s]:  All right. So let's keep going.
[2344s-2352s]:  So now I'm going to talk about some positive, a positive result. So the result that I'm going to talk
[2352s-2362s]:  about is this one here. Right, so I'm going to show you that the result that I'm going to show you
[2362s-2371s]:  this one here. Right, so I'm going to show you that on C3, C4 free graphs, token jumping is actually
[2371s-2378s]:  FPT and has a quadratic kernel, but again, what we will show is a stronger result.
[2379s-2383s]:  So what we will show is the following theorem. What we will show
[2386s-2390s]:  is can be summarized as follows. So if you look at any graph,
[2392s-2397s]:  or at any instance of the token jumping problem. So remember, an instance of token jumping has the
[2397s-2402s]:  input graph, the starting set, the target set, and K as the number of tokens.
[2404s-2413s]:  So let me try and draw something here. So if you look at your graph, you can kind of decompose it
[2413s-2420s]:  into something which is more or less as follows. So you have S, you have T, their intersection
[2420s-2430s]:  need not be empty. And then you have the neighborhood of S union T. And then you have the rest of the
[2430s-2438s]:  graph. So we're going to call the rest of the graph H. And we're going to call the close
[2438s-2448s]:  neighborhood of S union T, or if you will, this yellow part here, we call that J. Right, so we can
[2448s-2453s]:  think of our problem of our graph as being decomposed into those two areas, H and J.
[2455s-2464s]:  Okay, so the theorem states the following. If H is epsilon sparse, where epsilon sparse means
[2464s-2471s]:  that the number of edges is at most n squared minus epsilon positive epsilon. So if H is epsilon sparse,
[2472s-2483s]:  and J is C3 C4 free, then the problem admits a kernel, which is that big, K squared plus K into
[2483s-2490s]:  one plus one over epsilon. So notice now that we only need that H is epsilon sparse.
[2491s-2498s]:  And we only require C3 C4 freeness inside J, which is S union T close neighborhood.
[2499s-2510s]:  Close neighborhood of S union T. And this idea is actually is not a new idea. So this idea is
[2511s-2517s]:  okay, I had the drawing here, I should have used it. So the idea comes from has been used before.
[2518s-2523s]:  And it's what we call the buffer technique for the token jumping problem. And then the
[2523s-2528s]:  solution behind the buffer technique is very simple. So if I have S union T, but somewhere
[2529s-2536s]:  in the graph, which is not in the close neighborhood of S union T, I have a K-sized independent set,
[2536s-2544s]:  then you are done. Right, if I have a K-sized independent set in H, then you're done. You can
[2544s-2551s]:  basically take all the tokens on S, jump them into those independent yellow vertices in H,
[2551s-2558s]:  and then jump them back to T. So in some sense, when H has a large independent set, that's the easy
[2558s-2565s]:  case. Right, you're done. If you can find a large enough independent set in H, you're done.
[2566s-2571s]:  And that's what we call the buffer technique, because it's been also used to show that the problem
[2571s-2578s]:  is FBT on planar graphs, for example. Or K3J free graphs. So graphs without large bike links.
[2578s-2592s]:  So it's a well-known technique. All right. So what do we show? So we're going to use the buffer
[2592s-2600s]:  technique, and we're going to combine it with something else. So we show that you have a yes instance
[2601s-2609s]:  whenever one of those two conditions is true. The first condition is that H is epsilon sparse and
[2609s-2618s]:  contains more than this many vertices. And this is relatively easy. When you contain this many
[2618s-2624s]:  vertices and you are epsilon sparse, then you will have a K-sized independent set. And that's
[2624s-2630s]:  basically the buffer technique. When H is epsilon sparse and has that many vertices or more,
[2630s-2634s]:  then H is guaranteed to have an independent set of sparse K and you're done.
[2635s-2641s]:  So now you are stuck with what happens inside J or the closed neighborhood of S-Union T.
[2642s-2650s]:  And it turns out there, if you have C3C4-Frenus, the only thing you need on top of that to
[2650s-2654s]:  guarantee a yes instance is a vertex of degree at least 3K.
[2654s-2664s]:  So if you have C3C4-Frenus inside J and the vertex of degree 3K, then again you get a yes instance.
[2665s-2674s]:  So let me prove those two statements separately because they will be basically what we need for the
[2675s-2685s]:  final theorem. So the first lemma, as I told you, if H is epsilon sparse and has more than
[2685s-2690s]:  this many vertices, then it's a yes instance because you have a K-sized independent set in H.
[2691s-2697s]:  The idea of this proof is simple. It's a counting argument. And what you need to do basically
[2697s-2702s]:  first is to show that H must contain a vertex of degree less than and over K.
[2703s-2709s]:  And then basically you apply the standard greedy packing algorithm for constructing an independent set
[2709s-2715s]:  of sparse K. And the reason you show that the way you show that H has a vertex of degree less than
[2715s-2723s]:  and over K is, again, standard counting argument and the handshaking lemma. So if the minimum degree
[2723s-2728s]:  in H was at least n over K, then the number of edges would be at least n squared over 2K,
[2729s-2737s]:  which will only happen in an epsilon sparse graph when n is less than or equal 2K to the power 1 over
[2737s-2743s]:  S. And the rest of the proof is basically an induction on K.
[2745s-2750s]:  Okay, and so that shows you that when you do have an epsilon sparse graph with more than
[2750s-2758s]:  this many vertices, then we have a yes instance. All right, so how about the second part
[2759s-2766s]:  of the claim? So now what happens if we have a C3 C4 free J that has a vertex of degree 3K?
[2767s-2774s]:  Well, let's see what happens. So if we have a vertex of degree 3K and I'm going to circle it
[2774s-2780s]:  here in yellow. So how can the neighborhood of that vertex look? Well, we know that J is C3 free.
[2781s-2787s]:  So the blue edges cannot exist, which means that the neighborhood of the yellow vertex is an
[2787s-2795s]:  independent set inside J, not in the whole graph. Well, in fact, in the whole, well, no, because
[2796s-2803s]:  we're only talking about J as a sub-graph. Right? So the blue edges cannot exist, because otherwise
[2803s-2814s]:  we will get a C3 inside J. All right. So now let's look at the other vertices in S union T.
[2815s-2822s]:  The other, the second observation that you need is that any vertex other than the yellow vertex
[2822s-2829s]:  can have at most one neighbor in common with the yellow vertex. Because if you do have two neighbors
[2829s-2839s]:  in common, then you will get a C4. So now what happens if we have three K vertices in the
[2839s-2847s]:  neighborhood of the yellow vertex? Well, at most two K of them can be connected to some vertex in
[2847s-2855s]:  S union T, and you will get at least K of them, some K of them here that are only connected
[2856s-2863s]:  to the yellow vertex. And so now basically, instead of using a buffer inside H, we have just found
[2863s-2871s]:  a buffer inside J. And we can use the same strategy. We can jump all the tokens here, starting
[2871s-2876s]:  of course by the yellow token, and then jump them to where they need to go.
[2876s-2885s]:  So now combining those two
[2888s-2895s]:  observations, lemmas together, if you will, we get the following theorem. So if H is alpha
[2895s-2901s]:  sparse, and J is C3, C4, free, then the problem admits a kernel on this maneuver to C's.
[2902s-2907s]:  And it's basically a simple application of the previous two lemmas. If we have more than
[2907s-2914s]:  this many vertices in H, it's a trivial yes instance. If J has a vertex of degree 3K or more
[2914s-2919s]:  it's trivial yes instance, and now you combine all of this together, we know that S union T is
[2919s-2926s]:  of size at most 2K. We know that the neighborhood of S union T is of size at most 2K times 3K,
[2926s-2932s]:  which is roughly 6K squared. And now we know that the rest of the graph has at most that
[2932s-2938s]:  many vertices. So basically, you sum up those numbers and you get this bound.
[2946s-2952s]:  All right. So how does this theorem imply the result that I promised you to start with?
[2952s-2961s]:  So that token jumping and token sliding admit kernel with order K squared vertices.
[2963s-2969s]:  I mean, I mean, it also holds for bipartite C4 free graphs, right? Obviously because they are C3C4 free.
[2970s-2978s]:  So how do you get the kernel? Well, we know that J cannot contain more than 6K squared minus 2K
[2978s-2989s]:  vertices. And we know from a theorem from another paper that C3 free graphs with K squared over
[2989s-2995s]:  logk vertices must have an independent set of size at least K. And now we know that if H contains
[2995s-3003s]:  more than this many vertices, then we will get the yes instance as well. Right? So it becomes an
[3003s-3007s]:  immediate consequence of the previous theorem. But the previous theorem is even more general
[3007s-3012s]:  than this corollary. So this corollary does not really use the full power of this theorem.
[3016s-3023s]:  All right. That's it. I think I'm fine. If you have questions, I will take them now.
[3023s-3034s]:  So it was 55 minutes, right? For the talk. I did not go under the talk.
[3034s-3039s]:  It's fine. We usually allow plus minus 10 minutes. That's all right.
[3042s-3045s]:  So I have a question about token sliding. Yes.
[3046s-3053s]:  Yes. So how crucial what happens if one does not restrict the independent sets during the
[3053s-3061s]:  configuration to be not of the same size? Is that is that very critical for the difficulty or the
[3061s-3068s]:  easiness of the problem? Well, you have to be careful how you define that because in token sliding,
[3069s-3075s]:  tokens cannot leave the graph. That's correct. But the independent set sequence,
[3075s-3081s]:  all the independent sets have to be the same size, right? Or if not some token disappeared at some
[3081s-3088s]:  point, and I'm not sure how it disappeared. Right? Because you start with something of size K,
[3089s-3093s]:  and you're going to something of size K, you cannot leave the graph
[3094s-3100s]:  unless you define it in some way. So you will remain of size K throughout.
[3101s-3106s]:  But you can become slightly larger in K. But where does the new token come from?
[3109s-3115s]:  So there is a third rule that I did not tell you about, which is called token addition and removal.
[3116s-3123s]:  Under that rule, we actually allow you to remove vertices and adversities as long as you remain
[3123s-3132s]:  an independent set of size at least K. Does that answer your question?
[3132s-3143s]:  Yes. But in fact, it was shown that it was shown that so addition and removal is equivalent to token
[3143s-3150s]:  jumping. It never makes sense to add more tokens to your graph if you don't need them.
[3154s-3157s]:  You're only making your life harder into it if he's speaking.
[3161s-3163s]:  So the other question that I had is, I mean, I heard, I,
[3163s-3174s]:  so is it possible to view this whole problem on an exponential size graph where every vertex
[3175s-3184s]:  corresponds to an independent set in the original graph? And then you have edges between two vertices,
[3184s-3188s]:  if there is an edge between two vertices of the independent set. And now you are doing a
[3188s-3193s]:  reachability question. Is that a meaningful way to think about this?
[3193s-3200s]:  But that's exactly what we're doing. So the way you define your adjacency, I think, so you mean
[3200s-3206s]:  you define, you make two independent sets adjacent if one can be reached from the other via a single
[3206s-3211s]:  slide or a single joint. Exactly. Yeah, one edge here. There is one pair, you and B, which is adjacent.
[3212s-3214s]:  But that's exactly what we're doing.
[3214s-3220s]:  Okay, okay. Yeah. Right? I mean, if you, because we're looking at algorithms here,
[3220s-3226s]:  we kind of forget the structural picture behind it. But this algorithm is finding a path in this graph
[3226s-3232s]:  that you're describing. Yeah, yeah, that's it. And what we're saying is you can do it in FBT time
[3233s-3235s]:  or not depending on the problem we're talking about.
[3245s-3249s]:  Hi, Amir. Hi. Hi. How are you?
[3250s-3258s]:  Yeah, I'm good. So I had a question. So do problems remain equally hard if we bound the,
[3258s-3264s]:  if we have a restriction on the number of times, we can move the token to a particular vertex.
[3268s-3271s]:  The number of times you can move a token to a particular vertex.
[3272s-3276s]:  I like it. There are a lot of times the tokens can be moved to a vertex.
[3278s-3284s]:  Well, that's definitely going to change the complexity in, in at least intuitively speaking,
[3284s-3289s]:  right? Because now you're saying maybe it will, if you're bounding that by a constant,
[3289s-3294s]:  then you might be saying that I'm not allowing exponentially large sequences anymore.
[3295s-3301s]:  But in terms of exactly how the complexity changes, I don't have answers. I think it's a very
[3301s-3309s]:  nice question to pose. Even in terms of a non-parameterized complexity standard complexity,
[3309s-3314s]:  I think that that would be a very interesting question because it will definitely affect the
[3314s-3322s]:  behavior. I'm not sure exactly how yet. I don't know of any results that ask this particular question.
[3323s-3330s]:  Okay, so I had one more question in the W hardness result that you presented. So do you know what
[3331s-3339s]:  the length of the, the length of the changes, actually the number of changes or flips that you make
[3339s-3347s]:  in your independence. This is just, yes, yes, yes, we do. So here the number of changes is going to be
[3347s-3355s]:  where it's basically going to be the shortest possible sequence. So it's going to, it's basically
[3356s-3365s]:  going to be, so if you think about the simple construction, this one, it's basically literally
[3365s-3371s]:  going to be these guys are going to move here. So each is going to cost me one slide and then they're
[3371s-3377s]:  all going to, and now this guy is going to move here and now I will pay one slide for each one here.
[3379s-3384s]:  Now this is the simplified version of it. Once you go to the complete version of it, you have some
[3384s-3393s]:  extra slides within the path, but you can also count those. Okay, so but does this mean that, so
[3394s-3399s]:  does this mean that at a particular vertex, we are placing the token at most ones.
[3400s-3409s]:  In this case, yes. Okay. In this case, yes. Okay, so this problem should be hard even if we bound
[3409s-3419s]:  the number of times tokens can be moved to a vertex, right? Yes. Okay. Yes. So here in this case, yes.
[3419s-3429s]:  Absolutely. Okay. Thanks. So, Akansha, I have a remark about your question. So if a vertex,
[3431s-3437s]:  if a vertex cannot get a token to I's, then it somehow seems to be selecting disjoint
[3437s-3445s]:  independent sets, a sequence of them and that may have some bearing on coloring, just a top level top.
[3449s-3455s]:  So actually for the list, the W hardness case that I'm going to present it, it is exactly the case,
[3455s-3461s]:  right? So we are not allowed to move the token like twice on the same vertex.
[3462s-3469s]:  Yeah. So I didn't get your point of moving, so getting this disjoint independence, it's actually
[3470s-3475s]:  because if you say, if you think of it from my, the way I thought about it, right, that you are
[3475s-3480s]:  actually trying to find a path in a large graph where every vertex corresponds to an independent set,
[3480s-3488s]:  and you move from one independent set to another. What? So we can only move from one independent set to
[3488s-3496s]:  the other if the the changes is like in case of tokens sliding, it's one probably.
[3497s-3509s]:  Yeah. So it looks to be that you're asking for a collection of independence sets which are vertex
[3509s-3513s]:  disjoint, if the token sequence of independence sets which are vertex disjoint.
[3514s-3521s]:  Yeah. So if I may, I think I think a conscious question would be more relevant in a place where we
[3521s-3528s]:  don't have a monotone sequence, meaning a sequence. So we need a version of the problem or some
[3528s-3535s]:  cases of the problem where a vertex has to be visited multiple times to find solutions. And that
[3535s-3541s]:  is known to be the case for some versions or some statements of the problem. And in fact,
[3541s-3545s]:  the conscious also, this is also this was the crucial difference between piece-based completeness and
[3545s-3553s]:  NP completeness of sliding versus jumping in bipartite graphs. So it was because we were able to show
[3553s-3560s]:  that no vertex will be visited more than once. Okay. And the other problem. So so so that's why it's
[3560s-3565s]:  definitely an interesting question to pose, but you have to be careful in what context you pose it.
[3565s-3573s]:  Great. I don't know if that kind of settles, answers your question.
[3574s-3579s]:  Yes, yes it does. All right. Thanks. You're welcome.
[3587s-3588s]:  Any more questions?
[3595s-3624s]:  I guess not. Yeah, I don't think that I'm a motion scientist.
[3625s-3630s]:  Once again, announce the parameterized and go to them to 301 workshop, which is going to happen
[3630s-3636s]:  in December in the link has been posted once again in the chat. Some advanced topics in
[3636s-3641s]:  parameterized complexity will be discussed. Those interested can have a look and register for it.
[3643s-3647s]:  And yeah, if there are some more questions, please ask away.
[3655s-3678s]:  So anyone can register for the school?
[3679s-3680s]:  Yes, he's anyone can.
[3683s-3687s]:  Yeah, it's free and it's online and yeah, it's open to everyone.
[3688s-3691s]:  Awesome. So I can share it with my students as well. Of course, of course, please do.
[3691s-3696s]:  Yeah, that would be good. And we have zoomed some basic understanding of parameterized algorithms,
[3696s-3704s]:  but we have already shared a link on the page where students can go and go through some
[3704s-3710s]:  previous lectures in parameterized algorithms if they wish to just brace up or revise stuff.
[3717s-3725s]:  All right, so I guess, okay, I don't think there are any more questions. So I give this a good
[3725s-3731s]:  time to wrap up. So thank you once again, Professor Amitur for not going to give the talk.
[3731s-3736s]:  It was really nice to have you and it was really good to have something different than what we
[3736s-3742s]:  usually hear in a repair and trace complexity talk, at least most of them. So and yeah, these are really
[3742s-3748s]:  interesting problems to think of one. And thank you to the audience for being with us.
[3748s-3753s]:  And that's it for today's wrap up. See you all next week. Thank you. Bye.
